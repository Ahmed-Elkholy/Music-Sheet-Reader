{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from commonfunctions import *\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_page_contours(img):\n",
    "    img2, contours, hierarchy = cv2.findContours(img.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    return contours\n",
    "\n",
    "\n",
    "def find_largest_contour(contours):\n",
    "    contours_area_list = []\n",
    "    for contour in contours:\n",
    "        contours_area_list.append(cv2.contourArea(contour))\n",
    "        \n",
    "    index, value = max(enumerate(contours_area_list), key=operator.itemgetter(1))\n",
    "    return contours[index]\n",
    "\n",
    "\n",
    "def findApprox(contours):\n",
    "    ff = []\n",
    "    approx_list = []\n",
    "    for cnt in contours:\n",
    "        perimeter = cv2.arcLength(cnt, True)\n",
    "        approx = cv2.approxPolyDP(cnt, 0.03 * perimeter, True)\n",
    "\n",
    "        # Page has 4 corners and it is convex\n",
    "        if (len(approx) == 4):\n",
    "            maxArea = cv2.contourArea(approx)\n",
    "            ff.append(maxArea)\n",
    "            approx_list.append(approx) \n",
    "\n",
    "    index = findMax(ff)        \n",
    "    return approx_list[index]     \n",
    "\n",
    "\n",
    "def findMax(ff):\n",
    "    index, value = max(enumerate(ff), key=operator.itemgetter(1))\n",
    "    return index\n",
    "\n",
    "     \n",
    "def resize(img, height=800):\n",
    "    \"\"\" Resize image to given height \"\"\"\n",
    "    if (img.shape[0] > height):\n",
    "        ratio = height / img.shape[0]\n",
    "        return cv2.resize(img, (int(ratio * img.shape[1]), height))    \n",
    "    \n",
    "    \n",
    "def sortCornerPoints(points):\n",
    "    sorted_points = np.zeros_like(points)\n",
    "    sum_points = np.sum(points,axis=1)\n",
    "    sorted_points[0] = points[np.argmin(sum_points)]\n",
    "    sorted_points[2] = points[np.argmax(sum_points)]\n",
    "    diff_points = np.diff(points,axis=1)\n",
    "    sorted_points[1] = points[np.argmin(diff_points)]\n",
    "    sorted_points[3] = points[np.argmax(diff_points)]\n",
    "    return sorted_points           \n",
    "    \n",
    "    \n",
    "def transform_image(img,points):\n",
    "    w = max(np.linalg.norm(points[0]-points[1]),np.linalg.norm(points[2]-points[3]))\n",
    "    h = max(np.linalg.norm(points[0]-points[3]),np.linalg.norm(points[1]-points[2]))\n",
    "    dest_img = np.array([[0,0],[w-1,0],[w-1,h-1],[0,h-1]])\n",
    "    \n",
    "    dest_img = dest_img.astype(np.float32)\n",
    "    points = points.astype(np.float32)\n",
    "\n",
    "    Trans_Matrix = cv2.getPerspectiveTransform(points,dest_img)\n",
    "    cropped_img = cv2.warpPerspective(img, Trans_Matrix, (int(w), int(h)))\n",
    "    cv2.imwrite('output/gg.jpg',img)\n",
    "    cv2.imwrite('output/cropped_edge.jpg',cropped_img)\n",
    "    return cropped_img\n",
    "\n",
    "\n",
    "def rotate_with_lines(img):\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img_edges = cv2.Canny(img_gray, 100, 100, apertureSize=3)\n",
    "    lines = cv2.HoughLinesP(img_edges, 1, math.pi / 180.0, 100, minLineLength=100, maxLineGap=5)\n",
    "\n",
    "    angles = []\n",
    "\n",
    "    for x1, y1, x2, y2 in lines[0]:\n",
    "        angle = math.degrees(math.atan2(y2 - y1, x2 - x1))\n",
    "        angles.append(angle)\n",
    "\n",
    "    median_angle = np.median(angles)\n",
    "    img_rotated = ndimage.rotate(img, median_angle)\n",
    "    return img_rotated\n",
    "\n",
    "\n",
    "def crop_image(path):\n",
    "    img_org = cv2.imread(path)\n",
    "    \n",
    "    img_before = resize(cv2.imread(path))\n",
    "    img_gray = cv2.cvtColor(img_before, cv2.COLOR_BGR2GRAY)\n",
    "    img_edges = cv2.bilateralFilter(img_gray, 9, 75, 75)\n",
    "    img_edges = cv2.adaptiveThreshold(img_edges, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 115, 4)\n",
    "    img_edges = cv2.medianBlur(img_edges, 11)\n",
    "    img_edges = cv2.Canny(img_edges,200, 250)\n",
    "    img_edges = cv2.morphologyEx(img_edges, cv2.MORPH_CLOSE, np.ones((5, 11)))\n",
    "\n",
    "    cv2.imwrite('output/2_edge.jpg',img_edges)\n",
    "\n",
    "    pageContour = find_page_contours(img_edges)\n",
    "    con = find_largest_contour(pageContour)\n",
    "    epsilon = 0.01*cv2.arcLength(con,True)\n",
    "    approx = cv2.approxPolyDP(con,epsilon,True)\n",
    "    ff= findApprox(pageContour)\n",
    "\n",
    "    corner_points = sortCornerPoints(ff[:,0])*(img_org.shape[0]/800)\n",
    "    cv2.drawContours(img_before,[ff],0,(0,0,255),3)\n",
    "    cv2.imwrite('output/after_contour.jpg',img_before)\n",
    "\n",
    "    transformed_img = transform_image(img_org,corner_points)\n",
    "    return rotate_with_lines(transformed_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_image(img):\n",
    "\n",
    "    img_gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    img_edges = cv2.Canny(img_gray, 50, 150)\n",
    "    h_img,w_img,x = img.shape\n",
    "    thrsh = 120\n",
    "    img_edges = cv2.resize(img_edges, (w_img, h_img)) \n",
    "    img_edges[img_edges>=thrsh] = 255\n",
    "    img_edges[img_edges<thrsh] = 0\n",
    "    kernel = np.ones((50,50), np.uint8)\n",
    "    dilated_img = cv2.dilate(img_edges, kernel, iterations=1)\n",
    "    h,w = dilated_img.shape\n",
    "    flag = 0\n",
    "    cropHeight = 0\n",
    "    imgIndex = 0\n",
    "    cropped_imgs = list()\n",
    "    bound = int(h/45)\n",
    "\n",
    "    for y in range(h):\n",
    "        if dilated_img[y,int(w/2)] == 255 and flag == 0:\n",
    "            y_start = y\n",
    "            flag = 1\n",
    "        if dilated_img[y,int(w/2)] == 255 and flag == 1:\n",
    "            cropHeight +=1\n",
    "        if dilated_img[y,int(w/2)] == 0 and flag == 1:\n",
    "            flag = 0  \n",
    "            if cropHeight < 100:\n",
    "                continue\n",
    "            if imgIndex == 0:\n",
    "                imgIndex+=1\n",
    "                continue\n",
    "            crop_img = img[y_start-bound:y_start+cropHeight+bound, 50:w-50]\n",
    "            cropped_imgs.append(crop_img)\n",
    "            filename = 'output/cropped' + str(imgIndex) + '.jpg'\n",
    "            cv2.imwrite(filename,crop_img)\n",
    "            cropHeight = 0\n",
    "            imgIndex+=1\n",
    "    return cropped_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_ellipses(image):\n",
    "    gray_image = rgb2gray(image)*255\n",
    "    gray_image = (gray_image.astype(np.uint8)<128) * np.uint8(255)\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    gray_image = cv2.erode(gray_image, kernel, iterations=5)\n",
    "    gray_image = cv2.dilate(gray_image, kernel, iterations=5)\n",
    "    ellipses = gray_image>128\n",
    "    #gray_image[ellipses] = (255, 0, 0)\n",
    "    return ellipses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_lines_seg(img):\n",
    "    #bar(np.arange(img.shape[0]), 80 - np.sum(img,axis=1))\n",
    "    y = 80 - np.sum(img,axis=1)\n",
    "    maxnum = np.max(y) - 3\n",
    "    number_of_peaks = np.sum(y>maxnum)\n",
    "    thickness = number_of_peaks//5                         \n",
    "    img[y>maxnum] = 1\n",
    "    img_modified = img.copy()\n",
    "    img_modified = cv2.medianBlur(img_modified.astype(np.uint8), 5)\n",
    "    h, w = img_modified.shape\n",
    "    bound  = 6  \n",
    "    for y in range(bound , h - bound):\n",
    "        for x in range(w):\n",
    "            if img_modified[y,x] == 1 and img_modified[y-bound,x] == 0 and img_modified[y+bound,x] ==0:\n",
    "                img_modified[y,x] = 0\n",
    "    return img_modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_lines(img):\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    bin_img = cv2.adaptiveThreshold(gray_img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 115, 4)\n",
    "    #vertical \n",
    "    bin_img = bin_img/255\n",
    "    delta = 80\n",
    "    for i in range(0,bin_img.shape[1],delta):\n",
    "        bin_img[:,i:i+delta] = remove_lines_seg(bin_img[:,i:i+delta])\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    eroded_img = cv2.erode(bin_img,kernel,iterations = 2)\n",
    "    closed_img = cv2.dilate(eroded_img,kernel,iterations = 2)*255\n",
    "    return closed_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removal of ellipses and thresholding the image\n",
    "def remove_ellipses(ellipses,bin_img):\n",
    "    x_bin = bin_img > 128\n",
    "    #print(ellipses.shape, x_bin.shape)\n",
    "    x_bin[ellipses] = True\n",
    "    x_bin = x_bin.astype(np.uint8)*255\n",
    "    #x_bin = median(x_bin)\n",
    "    cv2.imwrite(\"test2.jpg\",x_bin)\n",
    "    return x_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_centers(img):\n",
    "    img_gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    img_gray[ellipses] = 255\n",
    "    img_gray[img_gray != 255] = 0\n",
    "    cv2.imwrite('ellipses.jpg',img_gray)\n",
    "    lbl = ndimage.label(img_gray)[0]\n",
    "    numberOfEllipses = np.max(lbl)\n",
    "    arr = list(range(1,numberOfEllipses+1))\n",
    "    centers = ndimage.measurements.center_of_mass(img_gray, lbl,arr)\n",
    "    centers = np.asarray(centers).astype(int)\n",
    "    return centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Main ######\n",
    "img = crop_image('imgs/2.jpg')\n",
    "segments = segment_image(img)\n",
    "imgIndex = 1\n",
    "for segment in segments:\n",
    "    bin_img = remove_lines(segment)\n",
    "    cv2.imwrite('test1.jpg',bin_img)\n",
    "    ellipses = detect_ellipses(segment)\n",
    "    centers  = detect_centers(segment)\n",
    "    img_no_ellipses = remove_ellipses(ellipses,bin_img)\n",
    "    #filename = 'output/ellipses' + str(imgIndex) + '.jpg'\n",
    "    #cv2.imwrite(filename,x)\n",
    "    #imgIndex+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLinesSpace(img):\n",
    "    img_gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    img_bin =  cv2.Canny(img_gray, 50, 150)\n",
    "    img_horizontal = np.copy(img_bin)\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    img_horizontal = cv2.dilate(img_horizontal, kernel, iterations=1)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 1))\n",
    "    img_horizontal = cv2.erode(img_horizontal, kernel, iterations=6)\n",
    "    img_horizontal = cv2.dilate(img_horizontal, kernel, iterations=16)\n",
    "    kernel = np.ones((4,2), np.uint8)\n",
    "    img_horizontal = cv2.erode(img_horizontal, kernel, iterations=1)\n",
    "    cv2.imwrite('output/Hor_Lines.jpg',img_horizontal)\n",
    "\n",
    "    lines = list()\n",
    "    h,w = img_horizontal.shape\n",
    "    for y in range(h):\n",
    "        count = 0\n",
    "        for x in range(int(w/2)-20,int(w/2)+20):\n",
    "            if img_horizontal[y,x] ==255:\n",
    "                count += 1\n",
    "            if count >= 10:\n",
    "                lines.append(y)\n",
    "                if len(lines)>1 and y - lines[-2] < 15:\n",
    "                    lines.remove(y)\n",
    "                break\n",
    "    avgSpace = 0            \n",
    "    for x in range(1,len(lines)):\n",
    "        avgSpace += (lines[x] - lines[x-1])\n",
    "    avgSpace /= 4\n",
    "    return int(avgSpace)\n",
    "\n",
    "\n",
    "img = cv2.imread('output/cropped4.jpg')\n",
    "print(getLinesSpace(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# May be used to allow for ellipse color detection later on\n",
    "def fill_ellipses(image):\n",
    "    data = np.copy(image)\n",
    "    # finds and number all disjoint white regions of the image\n",
    "    is_white = data > 128\n",
    "    labels, n = scipy.ndimage.measurements.label(is_white)\n",
    "\n",
    "    # get a set of all the region ids which are on the edge - we should not fill these\n",
    "    on_border = set(labels[:,0]) | set(labels[:,-1]) | set(labels[0,:]) | set(labels[-1,:])\n",
    "\n",
    "    for label in range(1, n+1):  # label 0 is all the black pixels\n",
    "        if label not in on_border:\n",
    "            # turn every pixel with that label to black\n",
    "            data[labels == label] = 0\n",
    "    return data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
